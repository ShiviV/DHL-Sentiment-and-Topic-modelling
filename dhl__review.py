# -*- coding: utf-8 -*-
"""DHL__Review.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1It_96Btyq0tKmWzDnIxScDHcCzS39DRI
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
nltk.download('punkt')
nltk.download('stopwords')
from nltk.corpus import stopwords
stop_words = stopwords.words('english')
from nltk import word_tokenize
from nltk import pos_tag
nltk.download('wordnet')
from nltk.stem.wordnet import WordNetLemmatizer
from nltk.corpus import wordnet
nltk.download('averaged_perceptron_tagger')
from nltk.tokenize import RegexpTokenizer
from nltk import PorterStemmer
from nltk.stem.snowball import SnowballStemmer
from wordcloud import WordCloud
import re
import string



df = pd.read_csv('Master_data.csv')

df.head()

df.info()

df.rename(columns={'reviewer_review': 'reviews'}, inplace=True)

df['reviews'].head(10)

df['reviews'] = df['reviews'].astype(str)

df['r_processed'] = [reviews.lower() for reviews in df['reviews']]

df['reviews'].head(10)

df['r_processed'][2]

def unnecessary_words(r_processed):
  return re.sub(r'\b\w{1,2}\b', '',r_processed)
df['r_processed'] = df['r_processed'].apply(lambda x: unnecessary_words(x))
df['r_processed'].head()

def cleaning_repeating_char(r_processed):
  return re.sub(r'(.)1+', r'1', r_processed)
df['r_processed'] = df['r_processed'].apply(lambda x: cleaning_repeating_char(x))
df['r_processed'].head()

def cleaning_URLs(r_processed):
  return re.sub(r'http\S+', ' ', r_processed)
  #return re.sub('((www.[^s]+)|(https?://[^s]+))'," ",r_processed)
df['r_processed'] = df['r_processed'].apply(lambda x: cleaning_URLs(x))
df['r_processed'].head()

#removing HTML tags
def remove_html(r_processed):
  html=re.compile(r'<.*?>')
  return html.sub(r'', r_processed)
df['r_processed'] = df['r_processed'].apply(remove_html)

def remove_com(r_processed):
  return re.sub(r"\ [A-Za-z]*\.com", " ", r_processed)
df['r_processed'] = df['r_processed'].apply(lambda x: remove_com(x))
df['r_processed'].head()

#cleaning and removing numeric numbers
def cleaning_numbers(r_processed):
  return re.sub('[0-9]+', '', r_processed)
df['r_processed'] = df['r_processed'].apply(lambda x: cleaning_numbers(x))
df['r_processed'].head()

def stripping_extra_spaces(r_processed):
  return re.sub(r' +', ' ', r_processed)
df['r_processed'] = df['r_processed'].apply(lambda x: stripping_extra_spaces(x))
df['r_processed'].head()

def clean(text):
    # Removes all special characters and numericals leaving the alphabets
    text = re.sub('[^A-Za-z]+', ' ', text)
    return text
df['r_processed'] = df['r_processed'].apply(clean)
df['r_processed']

mydata = pd.DataFrame(df[['reviews','r_processed']])

import nltk
 nltk.download('punkt_tab')

import nltk
nltk.download('averaged_perceptron_tagger_eng')

pos_dict = {'J': wordnet.ADJ, 'V': wordnet.VERB, 'N': wordnet.NOUN, 'R': wordnet.ADV}
def token_stop_pos(tweet_processed):
  tags = pos_tag(word_tokenize(tweet_processed))
  newlist = []
  for word, tag in tags:
    if word.lower() not in set(stopwords.words('english')):
      newlist.append(tuple([word, pos_dict.get(tag[0])]))
  return newlist
mydata['pos tagged'] = mydata['r_processed'].apply(token_stop_pos)
mydata.head()

wordnet_lemmatizer = WordNetLemmatizer()
def lemmatize(pos_data):
    lemma_rew = " "
    for word, pos in pos_data:
        if not pos:
            lemma = word
            lemma_rew = lemma_rew + " " + lemma
        else:
            lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)
            lemma_rew = lemma_rew + " " + lemma
    return lemma_rew

mydata['Lemmatized_sent'] = mydata['pos tagged'].apply(lemmatize)
mydata.head()

from textblob import TextBlob

# function to calculate subjectivity
def getSubjectivity(r_processed):
    return TextBlob(r_processed).sentiment.subjectivity

# function to calculate polarity
def getPolarity(r_processed):
    return TextBlob(r_processed).sentiment.polarity

# function to analyze the reviews
def analysis(score):
    if score <= 0:
        return 'Negative'
    elif score == 0:
        return 'Neutral'
    else:
        return 'Positive'

mydata['Polarity'] = mydata['Lemmatized_sent'].apply(getPolarity)
mydata['Analysis'] = mydata['Polarity'].apply(analysis)
mydata.head()

tb_counts = mydata.Analysis.value_counts()
tb_counts

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

tb_count= mydata.Analysis.value_counts()
plt.figure(figsize=(10, 7))
plt.pie(tb_counts.values, labels = tb_counts.index, autopct='%1.1f%%', shadow=False)
# plt.legend()

!pip install vaderSentiment

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
analyzer = SentimentIntensityAnalyzer()
# function to calculate vader sentiment
def vadersentimentanalysis(r_processed):
    vs = analyzer.polarity_scores(r_processed)
    return vs['compound']
mydata['Vader Sentiment'] = mydata['Lemmatized_sent'].apply(vadersentimentanalysis)

# function to analyse
def vader_analysis(compound):
    if compound >= 0.5:
        return 'Positive'
    elif compound <= -0.5 :
        return 'Negative'
    else:
        return 'Neutral'
mydata['Vader_Analysis'] = mydata['Vader Sentiment'].apply(vader_analysis)
mydata.head()

#count of sentiments with Neutral sentiment being considered
vader_counts = mydata['Vader_Analysis'].value_counts()
vader_counts

vader_counts= mydata['Vader_Analysis'].value_counts()
plt.figure(figsize=(10, 7))
plt.rcParams['font.size'] = '13'
plt.pie(vader_counts.values, labels = vader_counts.index, explode = (0.1, 0, 0), autopct='%1.1f%%', shadow=False)
plt.title("Overall Reviews")
plt.legend(fontsize = 11)

from wordcloud import WordCloud, ImageColorGenerator

def create_wordcloud(text):
  wc = WordCloud(background_color = 'white', max_words=3000, repeat=False)
  wc.generate(str(text))
  plt.imshow(wc, interpolation='bilinear')
  plt.axis('off')
  plt.show()
create_wordcloud(mydata['Lemmatized_sent'].values)

from sklearn.feature_extraction.text import CountVectorizer
countVectorizer = CountVectorizer()
countVector = countVectorizer.fit_transform(mydata['Lemmatized_sent'])
print('{} Number of tweets have {} words'.format(countVector.shape[0], countVector.shape[1]))


count_vect_df = pd.DataFrame(countVector.toarray(), columns = countVectorizer.get_feature_names_out())
count_vect_df

counts = pd.DataFrame(count_vect_df.sum())
count_df = counts.sort_values(0, ascending = False).head(20)
count_df

ind = count_df.index
val = [item for sublist in count_df.values for item in sublist]
plt.bar(ind, val)
plt.xticks(rotation=90)
plt.title('20 Most frequently used words')

word_cloud_df = mydata.loc[mydata['Vader_Analysis'] == 'Negative', :]
all_words = ' '.join([text for text in word_cloud_df['Lemmatized_sent']])

wordcloud = WordCloud(width=800, height=800, background_color='white', min_font_size=10).generate(all_words)

plt.figure(figsize=(8,8), facecolor=None)
plt.rcParams['font.size'] = '16'
plt.imshow(wordcloud)
plt.axis('off')
plt.tight_layout(pad=0)
plt.title('NEGATIVE SENTIMENTS')
plt.show()

word_cloud_df1 = mydata.loc[mydata['Vader_Analysis'] == 'Positive', :]
all_words = ' '.join([text for text in word_cloud_df1['Lemmatized_sent']])

wordcloud = WordCloud(width=800, height=800, background_color='white', min_font_size=10).generate(all_words)

plt.figure(figsize=(8,8), facecolor=None)
plt.rcParams['font.size'] = '16'
plt.imshow(wordcloud)
plt.axis('off')
plt.tight_layout(pad=0)
plt.title('POSITIVE SENTIMENTS: DURING COVID')
plt.show()

from nltk.util import ngrams
#tokens = mydata['Lemmatized_sent'].str.split()
#sequences = [tokens[i:] for i in range(3)]
#bigrams = zip(*sequences)
n_grams = ngrams(mydata['Lemmatized_sent'].str.split(), 3)
for grams in n_grams:
    print(grams)

#output = list(ngrams(mydata['Lemmatized_sent'], 5))
#print(output)

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(max_features=2500)
X = tfidf.fit_transform(mydata.Lemmatized_sent).toarray()
y = mydata.Vader_Analysis.map({'Positive': 1, 'Neutral': 0, 'Negative':-1}).values
featureNames = tfidf.get_feature_names_out()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=0)

X_train.shape, X_test.shape

from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(X_train, y_train)

## Testing the model on test set
y_pred = classifier.predict(X_test)
y_pred

from sklearn.metrics import confusion_matrix, accuracy_score
accuracy = accuracy_score(y_test, y_pred)
cm = confusion_matrix(y_test, y_pred)
print(cm)
print("The model accuracy is", accuracy )

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve, auc, matthews_corrcoef, cohen_kappa_score
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming y_test and y_pred are already defined (true labels and predicted labels)
accuracy = accuracy_score(y_test, y_pred)
cm = confusion_matrix(y_test, y_pred)

# Print confusion matrix and accuracy
print("Confusion Matrix:\n", cm)
print("The model accuracy is", accuracy)

# Print classification report for precision, recall, and f1-score
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Compute Matthews Correlation Coefficient (MCC)
mcc = matthews_corrcoef(y_test, y_pred)
print(f"Matthews Correlation Coefficient (MCC): {mcc:.4f}")

# Compute Cohen's Kappa
kappa = cohen_kappa_score(y_test, y_pred)
print(f"Cohenâ€™s Kappa: {kappa:.4f}")

# ROC Curve and AUC (if y_pred_proba is available, i.e., predicted probabilities)
# Uncomment below lines if you have predicted probabilities (for binary classification)
# fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
# roc_auc = auc(fpr, tpr)
# plt.figure()
# plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
# plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
# plt.xlim([0.0, 1.0])
# plt.ylim([0.0, 1.05])
# plt.xlabel('False Positive Rate')
# plt.ylabel('True Positive Rate')
# plt.title('Receiver Operating Characteristic')
# plt.legend(loc='lower right')
# plt.show()

# Confusion Matrix Heatmap
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix Heatmap')
plt.show()



"""The rows represent the true labels, and the columns represent the predicted labels.

Class -1: 7 correct predictions and 2 incorrect ones (predicted as class 0).

Class 0: 9 correct predictions, and there are no misclassifications for this class.

Class 1: 1 correct prediction with no misclassification.


The model has an accuracy of about 89.5%, which is a good indicator of how often the model is correct across all classes.

There can be a chance of overfitting also
"""





from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(max_depth = 15)
dt.fit(X_train,y_train)
dt.score(X_test,y_test)

featureImportance = pd.DataFrame({i : j for i,j in zip(dt.feature_importances_,featureNames)}.items(),columns = ['Importance','word'])
featureImportance.sort_values(by='Importance',ascending=False)

#plt.bar([x for x in range(len(featureImportance))], featureImportance)
#plt.show()