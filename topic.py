# -*- coding: utf-8 -*-
"""Topic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/109M_FEIsQUl_qRWg6jLHPu1Sc77yNKzD
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
nltk.download('punkt')
nltk.download('stopwords')
from nltk.corpus import stopwords
stop_words = stopwords.words('english')
from nltk import word_tokenize
from nltk import pos_tag
nltk.download('wordnet')
from nltk.stem.wordnet import WordNetLemmatizer
from nltk.corpus import wordnet
nltk.download('averaged_perceptron_tagger')
from nltk.tokenize import RegexpTokenizer
from nltk import PorterStemmer
from nltk.stem.snowball import SnowballStemmer
from wordcloud import WordCloud
import re
import string

df = pd.read_csv('Master_data.csv')

df.rename(columns={'reviewer_review': 'reviews'}, inplace=True)

df['reviews'].head(10)

df['reviews'] = df['reviews'].astype(str)

df['r_processed'] = [reviews.lower() for reviews in df['reviews']]

df['reviews'].head(10)

all_words = [word for tokens in df['reviews'] for word in tokens]
tweet_lengths = [len(tokens) for tokens in df['reviews']]
vocab = sorted(list(set(all_words)))

print('{} tokens total, with a vocabulary size of {}'.format(len(all_words), len(vocab)))
print('Max tweet length is {}'.format(max(tweet_lengths)))

word_length = []
for word in all_words:
    word_length.append(len(word))

print('average word size is {}'.format( sum(word_length) / len(word_length)))

less_than_3_tokens = df[df['reviews'].apply(lambda x: len(x) <= 3)].index

df.drop(less_than_3_tokens, inplace = True)

all_words = [word for tokens in df['reviews'] for word in tokens]
tweet_lengths = [len(tokens) for tokens in df['reviews']]
vocab = sorted(list(set(all_words)))

print('{} tokens total, with a vocabulary size of {}'.format(len(all_words), len(vocab)))
print('Max tweet length is {}'.format(max(tweet_lengths)))

flat_words = [item for sublist in df['reviews'] for item in sublist]

from nltk.probability import FreqDist # Import the FreqDist object from nltk.probability module

flat_words = [item for sublist in df['reviews'] for item in sublist]
word_freq = FreqDist(flat_words)

word_freq = FreqDist(flat_words)

!pip uninstall gensim -y
!pip install numpy==1.21.0
!pip install gensim

df['reviews'] = df['reviews'].astype(str)

df['reviews']

!pip install --upgrade numpy

pip install --upgrade gensim

df['reviews']

!pip uninstall numpy -y
!pip install numpy==1.21.0

!pip uninstall numpy -y

!pip install numpy==1.26.0

!pip install gensim

!pip uninstall gensim -y
!pip install numpy==1.21.0
!pip install gensim

!pip uninstall numpy -y
!pip install numpy==1.21.0
!pip install gensim

!pip uninstall numpy -y
!pip install numpy==1.21.0
!pip install gensim

!pip install numpy==1.26.4
!pip install gensim==4.3.3

from gensim.corpora import Dictionary
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem.wordnet import WordNetLemmatizer

# Ensure stopwords are downloaded
import nltk
nltk.download('stopwords')

stop_words = stopwords.words('english')
lemmatizer = WordNetLemmatizer()

def preprocess(df_text):
    """Preprocesses text data for LDA."""
    tokens = word_tokenize(df_text)
    # Relaxed filtering: keep words with length >= 2 (instead of > 3)
    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stop_words and len(token) >= 2]
    lemmatized = [lemmatizer.lemmatize(w) for w in stopwords_removed]
    # Keep words containing alphabets and numbers, allowing more terms
    processed = list(filter(lambda x: x.isalnum(), lemmatized))
    return processed

# Apply preprocessing
df['reviews'] = df['reviews'].apply(preprocess)

# Create dictionary
text_dict = Dictionary(df['reviews'])

# Less restrictive filtering: allow more terms
text_dict.filter_extremes(no_below=2, no_above=0.95) # Changed no_below to 2 and no_above to 0.95

# Proceed with creating the bow representation and LDA model
tweets_bow = [text_dict.doc2bow(tweet) for tweet in df['reviews']]
# ...

from gensim.corpora import Dictionary

text_dict = Dictionary(df.reviews) # Using df.reviews instead of df.text

text_dict.filter_extremes(no_below = 5, no_above = .90)

txt_out = text_dict.token2id

# for k, v in txt_out.items():
#     print(k,v)

tweets_bow = [text_dict.doc2bow(tweet) for tweet in df['reviews']]

tweets_bow[0]

from gensim.models.ldamodel import LdaModel # Importing the LdaModel class

k = 5
tweets_lda = LdaModel(tweets_bow,
                      num_topics = k,
                      id2word = text_dict,
                      random_state = 1,
                      passes=10)

tweets_lda.show_topics()

"""Topic 0: Customer service and contact details
Key Words: dhl, phone, number, home, parcel, delivery, service

Description: This topic seems to be about issues related to customer service, including contact details (e.g., phone numbers), parcels, and home delivery.

Topic 1: Delivery delays and review
Key Words: day, company, still, delivery, dhl, review, star, waiting

Description: This topic focuses on delivery delays (still waiting), reviews, and customer frustration related to delivery times.

Topic 2: DHL service and delivery time
Key Words: service, dhl, time, driver, day, customer, delivered

Description: This topic appears to be centered around the quality of DHL's service and delivery times, including feedback on drivers and delivery efficiency.

Topic 3: Parcel and delivery issues
Key Words: parcel, delivery, march, depot, driver, day, sender, said, dhl

Description: This topic is related to issues with parcels and deliveries, including the involvement of depots, drivers, and certain dates like "March" when the delivery is expected.

Topic 4: Delivery and package handling
Key Words: package, day, dhl, door, left, delivery, company, review

Description: This topic highlights issues related to packages being left at the door, delays, and reviews, with a focus on delivery handling.


"""

def format_topics_sentences(ldamodel=None, corpus=tweets_bow, texts=df['reviews']):
    # Init output
    sent_topics_df = pd.DataFrame()
    sent_topics_data = [] #list to hold data before creating dataframe
    # Get main topic in each document
    for i, row_list in enumerate(ldamodel[tweets_bow]):
        row = row_list[0] if ldamodel.per_word_topics else row_list
        # print(row)
        row = sorted(row, key=lambda x: (x[1]), reverse=True)
        # Get the Dominant topic, Perc Contribution and Keywords for each document
        for j, (topic_num, prop_topic) in enumerate(row):
            if j == 0:  # => dominant topic
                wp = ldamodel.show_topic(topic_num)
                topic_keywords = ", ".join([word for word, prop in wp])
                #sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)
                # Append data as a list to sent_topics_data
                sent_topics_data.append([int(topic_num), round(prop_topic,4), topic_keywords])
            else:
                break
    # Create DataFrame outside the loop
    sent_topics_df = pd.DataFrame(sent_topics_data, columns=['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords'])
    # Add original text to the end of the output
    contents = pd.Series(texts)
    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)
    return(sent_topics_df)


df_topic_sents_keywords = format_topics_sentences(ldamodel=tweets_lda, corpus=tweets_bow, texts=df['reviews'])

# Format
df_dominant_topic = df_topic_sents_keywords.reset_index()
df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']
df_dominant_topic.head(10)

df_dominant_topic.head(20)

import math # Importing the math module
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec # Importing the gridspec module

def plot_top_words(lda=tweets_lda, nb_topics=k, nb_words=10):
    top_words = [[word for word,_ in lda.show_topic(topic_id, topn=50)] for topic_id in range(lda.num_topics)]
    top_betas = [[beta for _,beta in lda.show_topic(topic_id, topn=50)] for topic_id in range(lda.num_topics)]

    gs  = gridspec.GridSpec(round(math.sqrt(k))+1,round(math.sqrt(k))+1)
    gs.update(wspace=.5, hspace=.5)
    plt.figure(figsize=(30,20))
    for i in range(nb_topics):
        ax = plt.subplot(gs[i])
        plt.barh(range(nb_words), top_betas[i][:nb_words], align='center',color='blue', ecolor='black')
        ax.invert_yaxis()
        ax.set_yticks(range(nb_words))
        ax.set_yticklabels(top_words[i][:nb_words])
        plt.title("Topic "+str(i))

plot_top_words()

!pip install pyLDAvis

import pyLDAvis.gensim

pyLDAvis.enable_notebook()

vis = pyLDAvis.gensim.prepare(tweets_lda, tweets_bow, dictionary=tweets_lda.id2word)
vis

df_dominant_topic.head(20)

from gensim.models.ldamodel import LdaModel # Importing the LdaModel class

k = 4
tweets_lda = LdaModel(tweets_bow,
                      num_topics = k,
                      id2word = text_dict,
                      random_state = 1,
                      passes=10)

tweets_lda.show_topics()

import pyLDAvis.gensim

pyLDAvis.enable_notebook()

vis = pyLDAvis.gensim.prepare(tweets_lda, tweets_bow, dictionary=tweets_lda.id2word)
vis

"""Topic 0: Parcel delivery and logistics issues
Key Words: delivery, march, parcel, said, sender, driver, service, depot

Description: This topic revolves around parcel delivery issues, including delays, communication (e.g., "said"), and concerns regarding drivers and depots. It also references a specific time frame ("March"), indicating potential delivery issues around that time.

Topic 1: Delivery tracking and delays
Key Words: day, dhl, parcel, delivered, address, time, item, phone, still, another

Description: This topic highlights concerns with the delivery process, focusing on delays, incorrect addresses, and issues with parcel tracking. Words like "still" and "delivered" suggest customers are frustrated with delivery status updates.

Topic 2: DHL service quality
Key Words: dhl, service, day, customer, time, company, package, number, could

Description: This topic concerns the general quality of service provided by DHL. Customers may be expressing dissatisfaction with service timing, customer support, or package handling. The word "could" suggests that there may be suggestions for improvement.

Topic 3: Delivery attempts and logistics
Key Words: parcel, dhl, delivery, hour, driver, depot, attempt, march, time

Description: This topic focuses on delivery attempts and issues related to timing (e.g., delivery attempts made within certain hours) and locations (e.g., depots). "Attempt" suggests that some parcels may not have been delivered successfully, resulting in frustration.
"""



from gensim.models.ldamodel import LdaModel # Importing the LdaModel class

k = 3
tweets_lda = LdaModel(tweets_bow,
                      num_topics = k,
                      id2word = text_dict,
                      random_state = 1,
                      passes=10)

tweets_lda.show_topics()

"""Topic 0: Delivery and parcel handling issues
Key Words: parcel, delivery, march, dhl, depot, driver, said, home, hour, day

Description: This topic primarily focuses on delivery issues, with mentions of "parcel," "delivery," and "depot" indicating logistical problems. Words like "march" and "driver" suggest there might have been specific delivery delays or difficulties related to scheduling or location. The inclusion of terms like "said" and "home" indicates some communication or delivery attempt at the customerâ€™s home.

Topic 1: Delivery tracking, address issues, and delivery status
Key Words: day, dhl, parcel, phone, delivered, address, item, time, still, another

Description: This topic reflects customer frustration with delivery status and address accuracy. Keywords like "still" and "delivered" highlight ongoing delays or confusion about the delivery's status. The presence of terms like "phone" and "address" suggests that there might be issues with updating or confirming delivery details, including potential mistakes or miscommunication about delivery addresses.

Topic 2: Service quality concerns
Key Words: dhl, service, day, would, customer, time, package, company, bad, number

Description: This topic centers around customer service and service quality. The use of words like "bad," "service," and "company" suggests that some customers are dissatisfied with the overall service experience. There are also mentions of "time" and "package," pointing to delays or issues related to delivery timeframes or package handling.


"""



import pyLDAvis.gensim

pyLDAvis.enable_notebook()

vis = pyLDAvis.gensim.prepare(tweets_lda, tweets_bow, dictionary=tweets_lda.id2word)
vis

import gensim
from gensim.models import LdaModel
from gensim.models.coherencemodel import CoherenceModel
from gensim.corpora import Dictionary
import matplotlib.pyplot as plt

# Assuming you have a preprocessed corpus and dictionary
# Example:

# Get the necessary data from the previously created DataFrame (df_dominant_topic)
# This will be used as the corpus for coherence calculation
sent_topics_data = df_dominant_topic[['Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords']].values.tolist()

# Assign the dictionary
dictionary = text_dict  # Make sure 'text_dict' is the dictionary created earlier

# Assign the text data
texts = df['reviews']  # Make sure 'df' and 'reviews' are the DataFrame and column containing the preprocessed texts

# Range of topics to test (e.g., 3 to 7 topics)
topic_range = range(3, 8)
coherence_scores = []

for num_topics in topic_range:
    # Create and train the LDA model for the current number of topics
    lda_model = LdaModel(corpus=tweets_bow, num_topics=num_topics, id2word=dictionary, passes=15)  # Use tweets_bow as corpus

    # Compute coherence score for the model
    coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')
    coherence_score = coherence_model_lda.get_coherence()

    # Append the coherence score to the list
    coherence_scores.append(coherence_score)

    print(f"Number of Topics: {num_topics}, Coherence Score: {coherence_score}")

# Plot the coherence scores for different number of topics
plt.plot(topic_range, coherence_scores)
plt.xlabel("Number of Topics")
plt.ylabel("Coherence Score")
plt.title("Coherence Scores for Different Numbers of Topics")
plt.show()

"""7 Topics has the highest coherence score of 0.302, meaning it produces the most coherent and meaningful topics according to the metric.

4 Topics and 5 Topics also show relatively high coherence, but 7 Topics outperforms them.

6 Topics and 3 Topics have lower coherence scores, which suggests that these models may not be as effective in capturing the structure of the data.
"""